---
title: "Graduation Project"
author: "Mashael Abdullah Al-Saeed"
date: "30\x0F/7\x0F/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Study Case: churning customers from a Telecom company. 

## Background Story 

Now that you have taken an amazing course with your nice teacher the Arabian Analyst you decided to open a data science consulting firm. Your first customer is a Telecom company that is trying to figure out the reasons why customers are switching to their competitors.  During your meeting with the CEO Ola, she told you that she is interested to develop a model that help her company to determin which customers are likely to switch *Churn* to their competitors. She also provided you with the company data and description. 

## Dataset information. 

The data set contains 20 predictors worth of information about 3000 customers, along with the target variable, churn, an indication of whether that customer churned (left the company) or not  

The variables are as follows: 

    • State: Categorical for the 50 states and the District of Columbia. 
    • Accountlength: Integer-valued, how long account has been active. 
    • Areacode: Categorical 
    • Phonenumber: Essentially a surrogate for customerID. 
    • Internationalplan: Dichotomous categorical yes or no. . 
    • Voicemailplan: Dichotomous categorical yes or no. 
    • Numberofvoicemailmessages: Integer-valued. 
    • Totaldayminutes: Continuous minutes customer used service during the day. 
    • Totaldaycalls: Integer-valued. 
    • Totaldaycharge: Continuous perhaps based on above two variables. 
    • Total eve minutes: Continuous, minutes customer used service during the evening. 
    • Totalevecalls: Integer-valued. 
    ##maybe there is correlation>>
    • Totalevecharge: Continuous perhaps based on above two variables. 
    • Total night minutes: Continuous, minutes customer used service during the night. 
    • Totalnightcalls: Integer-valued. 
    ##maybe there is correlation>>
    • Totalnightcharge: Continuous perhaps based on above two variables.  
    • Total international minutes: Continuous, minutes customer used service to make international calls. 
    • Totalinternationalcalls: Integer-valued. 
    ##maybe there is correlation>>
    • Totalinternationalcharge:  Continuous perhaps based on above two variables. 
    • Numberofcallstocustomerservice:  Integer-valued. 
    • Churn: Target.Indicator of whether the customer has left the company (true or false).
    
## Analysis 

### Setp 1: Importing the Data

```{r Importing the data}
# use read.csv or read_csv from readr packages 
library(readr)
dataset <- read_csv("churn_df.csv")
head(dataset)
```

### Setp 2: Split the dataset into training and testing sets

```{r}
# use createDataPartition() from caret package or use the sample() from base R. 
library("caret")

set.seed(100)

trainRowNumbers <- createDataPartition(dataset$Churn., p = .7, list = FALSE)

trainData <- dataset[trainRowNumbers,]

testData <- dataset[-trainRowNumbers,]

x = trainData[,1:21]

y = trainData$Churn.


```



### Setp 3: Descriptive statistics

```{r}
# use summary() function or perform more advance descriptive statistics using dplyr package

#summary(dataset)



```


Write you analysis from Descriptive statistics here .... 


#### BONUS Step 3.1 : Exploratory Analysis
```{r}

# use ggplot to explore :
  # data centrality 
  # data variability 
  # data shape 
  # outliers 

```



Write you analysis from Exploratory Analysis here .... 


##### Correlations 
```{r}
# Describe the relationship between variables 
#dropping char variables so cor functions dont return error
sapply(dataset, class)
#  VMail.Plan
#  Churn. 
#   Phone  
#  Int.l.Plan 
#  State

correlated_data <- cor(dataset[sapply(dataset, function(x) ! is.character(x))], use = "pairwise.complete.obs")

correlated_data

findCorrelation(correlated_data, cutoff = .50, verbose = FALSE, names = TRUE)



# the output is: 16, 7, 11, 10 or "Intl.Charge","Day.Charge","Night.Mins","Eve.Charge"
#now we should delete the predictors that findCorrelation functioon determine
#X1 colomn is only number it don't explain anything about data and will interfer with data when we use model
df = subset(dataset, select = -c(X1,Intl.Charge,Day.Charge,Night.Mins,Eve.Charge))

df

```

Write you analysis from Correlations here .... 


*hint*: identify highly correlated variables and explain why we should not include them. 



##### Histograms

```{r}
# use ggplot package with geom_histogram() or hist() from base R. 
library(reshape2)
#convert wide to long 
melt.df <- melt(df)
head(melt.df)
#small multiple chart to visualize all variables
ggplot(data = melt.df, aes(x = value)) + 
stat_density() + 
facet_wrap(~variable, scales = "free")

```


Write you analysis from Histograms here .... 
*hint*: identify skewed variables and determine if you need to do transformation on them or not. Justify your decision. 
most of variabales are in normal distrbution, but there are 4 variabales wich needs to be transformes>
- Area.Code: i think it is bimodal 
- VMail.Message:
- intl.Class: right skewed.
- CustServ.Calls:  i think it is right skewed, but it has lots of missing data.

##### Scatterplots 

```{r}
# use ggplot package with geom_point() or plot() from base R. 
pairs(~Account.Length+Area.Code+VMail.Message+Day.Mins+Day.Calls+Eve.Mins+Eve.Calls+Night.Calls+Night.Charge+Intl.Mins+Eve.Calls+Night.Calls+Night.Charge+Intl.Mins+Intl.Calls+CustServ.Calls,data=df,
   main="Simple Scatterplot Matrix")


```

Write you analysis from Scatterplots here .... 

#### Boxplots 

```{r}
# use ggplot package with geom_boxplot() or boxplot() from base R


numeric_data <- df[sapply(df, function(x) ! is.character(x))]

boxplot(numeric_data~Account.Length+Area.Code+VMail.Message+Day.Mins+Day.Calls+Eve.Mins+Eve.Calls+Night.Calls+Night.Charge+Intl.Mins+Intl.Calls+CustServ.Calls)
```
```{r}
#how many customers churned?
table(dataset$Churn.)
# 440 customers churned

```

Write you analysis from Boxplots here .... 


### Setp 4: handling missing data

```{r}
# use any method to determin if there is missing data or not. This include 
# Identify if there is a character to indicate missing data. e.g -1, "", 9999
# If the data is actually recognize by your R as NA, that is asweome 
# anyNA(), skim_to_wide() from the skimr package.

library("skimr")

skimmed <- skim_to_wide(df)

skimmed
#variabales with missing data:
#Int.l.plan:300
#Phone:299
#Eve.calls:292
#VMail.Message:283
sum(is.na(df))
mean(is.na(df))

#since missing data are few less than 0.1 we omit the NA 
complete_df <- na.omit(df)


anyNA(complete_df)
```





### Setp 5: Create dummy variables for categorical data


```{r}
# Use dummyVars() from caret package or perform the conversion manually. 
#char variabales in our datset ar:
#1.Churn : wich is our dependent variablae, we should create dummy variabale
#2.Phone: we dont need phone number so we delete it
#3.state: ال
#4.Intl.l.plan:
#5.Vmail.plan:
df1 <- subset(df, select = -c(Phone))

dmy <- dummyVars("~.", data = df1)

df2 <- data.frame(predict(dmy, newdata = df1))

df2
```




Describe which categorical variables did you convert to dummy variables and why you chose them. 




### Setp 6: Data Normalization and Transformation

```{r}
# Use perProcess() from caret package or perform the conversion manually. 


df2$Intl.Calls <- log(df2$Intl.Calls)

df2 <- subset(df2, select = -c(CustServ.Calls,Area.Code,VMail.Message))

df2

```

Explain why it is important to normalize the data. Moreover, based on what you decision after performing histograms, you should perform all necessary transformation here.


### Setp 7: Training and Tuning Model

```{r}
# use train() from caret package or select your chose from any one of the models we discussed during this course

glm.fit(formula = Churn. ~ State + Account.Length + Int.l.Plan + VMail.Plan + Day.Mins + Day.Calls + Eve.Mins + Eve.Calls + Night.Calls + Night.Charge + Intl.Mins + Intl.Calls, data = df2, family = binomial)
#logistic regression because the response variable is binomial variable
```

justify why you chose the model you did and discuss ways that this model could be improved. 

*hint*: use cross validation and fine tune your model by using a grid search. 

### Setp 8: Testing and Evaluating the model


```{r}
# use the confusionMatrix() from caret package or confusion() form DAAG package. 
# make sure that the output data is in the right format for those functions. 
```


Discuss your results and explain why your model is performing well or not well. 



